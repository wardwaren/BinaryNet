{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ALBu3xLB5FL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "#from logger import Logger\n",
        "from binaryNet import Binary_W, Binary, Threshold\n",
        "from argparse import Namespace"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfT74qRsCGX9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "9df64596-84e6-4ca0-ff1e-c94a908f601f"
      },
      "source": [
        "\n",
        "# Training settings\n",
        "parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
        "parser.add_argument('--batch-size', type=int, default=100, metavar='N',\n",
        "                    help='input batch size for training (default: 64)')\n",
        "parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
        "                    help='input batch size for testing (default: 1000)')\n",
        "parser.add_argument('--epochs', type=int, default=12, metavar='N',\n",
        "                    help='number of epochs to train (default: 10)')\n",
        "parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
        "                    help='learning rate (default: 0.01)')\n",
        "parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
        "                    help='SGD momentum (default: 0.5)')\n",
        "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
        "                    help='disables CUDA training')\n",
        "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
        "                    help='random seed (default: 1)')\n",
        "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
        "                    help='how many batches to wait before logging training status')\n",
        "parser.add_argument('--num_th', type=int, default=1, metavar='N',\n",
        "                    help='how many batches to wait before logging training status')\n"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--num_th'], dest='num_th', nargs=None, const=None, default=1, type=<class 'int'>, choices=None, help='how many batches to wait before logging training status', metavar='N')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr6jXK0STpu_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "fef435a3-5381-403b-da13-a96eec60f809"
      },
      "source": [
        "r = torch.linspace(0, 1, steps=6)\n",
        "for i in list(zip(r,r[1:]))[1:]:\n",
        "  print(str(i[0]) + \" \" + str(i[1]))"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.2000) tensor(0.4000)\n",
            "tensor(0.4000) tensor(0.6000)\n",
            "tensor(0.6000) tensor(0.8000)\n",
            "tensor(0.8000) tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf6K-aBcCKLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args = Namespace(batch_size=100, epochs=12, log_interval=10, lr=0.01, momentum=0.5, no_cuda=False, num_th=5, seed=1, test_batch_size=1000)\n",
        "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "torch.manual_seed(args.seed)\n",
        "if args.cuda:\n",
        "    torch.cuda.manual_seed(args.seed)\n",
        "\n",
        "data_folder = './data'\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(data_folder, train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(data_folder, train=False, transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=args.batch_size, shuffle=True, **kwargs)\n"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cihhWo2wCyX-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#kwargs = {'num_workers': 2, 'pin_memory': True} if args.cuda else {}\n",
        "#train_loader = torch.utils.data.DataLoader(\n",
        "#    datasets.CIFAR10(data_folder, train=True, download=True,\n",
        "#                   transform=transforms.Compose([\n",
        "#                       transforms.RandomCrop([28, 28]),\n",
        "#                       transforms.ToTensor(),\n",
        "#                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "#\n",
        "#                   ])),\n",
        "#    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
        "#test_loader = torch.utils.data.DataLoader(\n",
        "#    datasets.CIFAR10(data_folder, train=False, transform=transforms.Compose([\n",
        "#                       transforms.RandomCrop([28, 28]),\n",
        "#                       transforms.ToTensor(),\n",
        "#                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "#\n",
        "#                   ])),\n",
        "#    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "\n",
        "def to_np(x):\n",
        "    return x.data.cpu().numpy()\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, t):\n",
        "        super(Net, self).__init__()\n",
        "        self.t = t\n",
        "        self.conv1 = nn.Conv2d(self.t, 10, kernel_size=5)\n",
        "       # self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(16*20, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "        self.bn0 = nn.BatchNorm2d(1)\n",
        "        self.bn1 = nn.BatchNorm2d(10)\n",
        "        self.bn2 = nn.BatchNorm2d(20)\n",
        "        self.bn3 = nn.BatchNorm1d(50)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.th(x, self.t)\n",
        "        im = x\n",
        "        x,w = self.binary_w(x, self.conv1)\n",
        "        x = F.conv2d(x,w)\n",
        "        x = F.tanh(F.max_pool2d(self.bn1(x), 2))\n",
        "        x,w = self.binary_w(x,self.conv2)\n",
        "        x = F.conv2d(x,w)\n",
        "        x = F.tanh(F.max_pool2d(self.bn2(x), 2))\n",
        "        x = self.binary(x)\n",
        "        x = x.view(-1, 16*20)\n",
        "        x = F.tanh( self.bn3(self.fc1(x)))\n",
        "    #    x = self.binary(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x, im\n",
        "\n",
        "    def binary(self, input):\n",
        "        return Binary().apply(input)\n",
        "\n",
        "    def binary_w(self, input, param):\n",
        "       return Binary_W().apply(input, param.weight)\n",
        "\n",
        "    def th(self, input, t):\n",
        "        \n",
        "        return Threshold().apply(input, t)\n"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEKlldqgFQkN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models = []\n",
        "for i in range(1,6):\n",
        "  model = Net(i)\n",
        "  model.to(device)\n",
        "  models.append(model)\n",
        "\n",
        "# Set the logger\n",
        "#logger = Logger('./logs')\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
        "#optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "i = 0\n"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6anvXQ5FTuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def train(epoch):\n",
        "    for model in models:\n",
        "        model.train()\n",
        "    \n",
        "    step = (epoch-1)*len(train_loader.dataset)/100\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = []\n",
        "        for model in models:\n",
        "            output, im1 = model(data)\n",
        "            outputs.append(output)\n",
        "        \n",
        "        output = outputs[0]\n",
        "        for i in range(1,5):\n",
        "            output += outputs[i]\n",
        "        \n",
        "        output /= 5\n",
        "        #loss = F.nll_loss(output, target)\n",
        "        loss = criterion(output, target)\n",
        "        if loss.item()<10.0:\n",
        "            #print ('True')\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.00f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "            # Compute accuracy\n",
        "            _, argmax = torch.max(output, 1)\n",
        "            accuracy = (target == argmax.squeeze()).float().mean()\n",
        "#            #============ TensorBoard logging ============#\n",
        "            # (1) Log the scalar values\n",
        "#            info = {\n",
        "#                'loss': loss.data[0],\n",
        "#                'accuracy': accuracy.data[0]\n",
        "#            }\n",
        "#\n",
        "#            for tag, value in info.items():\n",
        "#                logger.scalar_summary(tag, value, step+1)\n",
        "##\n",
        "#            # (2) Log values and gradients of the parameters (histogram)\n",
        "#            for tag, value in model.named_parameters():\n",
        "#                tag = tag.replace('.', '/')\n",
        "#                logger.histo_summary(tag, to_np(value), step+1)\n",
        "#              #  logger.histo_summary(tag+'/grad', to_np(value.grad), step+1)\n",
        "##\n",
        "#            # (3) Log the images\n",
        "#            info = {\n",
        "#                'images': to_np(im1.view(100,model.t, 28,28))[:10, 5:8, :, :]\n",
        "#            }\n",
        "#\n",
        "#            for tag, images in info.items():\n",
        "#                logger.image_summary(tag, images, step+1)\n"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Itipr501FWGO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def adjust_learning_rate(lr, optimizer, epoch):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 after 3 and 6 epochs\"\"\"\n",
        "    lr = lr * (0.1 ** (epoch // 6))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Du7F3n5AFXmu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def test(epoch):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        with torch.no_grad():\n",
        "            output, im1 = model(data)\n",
        "        test_loss += criterion(output, target).item()\n",
        "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(target.data).cpu().sum()\n",
        "\n",
        "    test_loss = test_loss\n",
        "    test_loss /= len(test_loader) # loss function already averages over batch size\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMJ6T0PqFxJ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cca69426-2f76-451e-b16a-3cf9b00af4a2"
      },
      "source": [
        "\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    adjust_learning_rate(args.lr, optimizer, epoch)\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.356657\n",
            "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 2.286415\n",
            "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 2.302324\n",
            "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 2.259698\n",
            "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 2.293200\n",
            "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 2.274897\n",
            "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 2.253546\n",
            "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 2.207810\n",
            "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 2.237907\n",
            "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 2.266114\n",
            "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 2.209687\n",
            "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 2.207905\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 2.201289\n",
            "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 2.206156\n",
            "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 2.165933\n",
            "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 2.207458\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 2.179159\n",
            "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 2.188014\n",
            "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 2.169506\n",
            "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 2.180718\n",
            "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 2.138135\n",
            "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 2.124019\n",
            "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 2.146440\n",
            "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 2.110628\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 2.064926\n",
            "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 2.122114\n",
            "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 2.093905\n",
            "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 2.113506\n",
            "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 2.053239\n",
            "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 2.082474\n",
            "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 2.042624\n",
            "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 2.049830\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.056742\n",
            "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 2.001809\n",
            "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 2.080353\n",
            "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 2.070286\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 2.000804\n",
            "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 2.018291\n",
            "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 2.015819\n",
            "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 2.044106\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 1.994111\n",
            "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 2.001396\n",
            "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 1.988617\n",
            "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 1.972806\n",
            "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 1.992413\n",
            "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 1.997912\n",
            "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 2.015325\n",
            "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 1.950901\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 1.977794\n",
            "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 1.992727\n",
            "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 1.920110\n",
            "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 1.913410\n",
            "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 1.986186\n",
            "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 1.992046\n",
            "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 1.907123\n",
            "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 1.898178\n",
            "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 1.925212\n",
            "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 1.896407\n",
            "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 1.911068\n",
            "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 1.915952\n",
            "\n",
            "Test set: Average loss: 1.0798, Accuracy: 6764/10000 (67.64%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.868466\n",
            "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 1.890277\n",
            "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 1.823117\n",
            "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 1.872440\n",
            "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 1.797252\n",
            "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 1.870370\n",
            "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 1.787848\n",
            "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 1.815092\n",
            "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 1.800884\n",
            "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 1.785191\n",
            "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 1.878761\n",
            "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 1.781903\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 1.815134\n",
            "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 1.760327\n",
            "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 1.753384\n",
            "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 1.803352\n",
            "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 1.811727\n",
            "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 1.799672\n",
            "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 1.722868\n",
            "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 1.683860\n",
            "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 1.727100\n",
            "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 1.707093\n",
            "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 1.736641\n",
            "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 1.727764\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 1.656823\n",
            "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 1.794000\n",
            "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 1.792128\n",
            "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 1.673429\n",
            "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 1.664043\n",
            "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 1.670987\n",
            "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 1.709121\n",
            "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 1.672867\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 1.644534\n",
            "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 1.700172\n",
            "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 1.630335\n",
            "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 1.610969\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 1.628410\n",
            "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 1.613166\n",
            "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 1.581312\n",
            "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 1.627210\n",
            "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 1.656412\n",
            "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 1.496307\n",
            "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 1.699332\n",
            "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 1.558555\n",
            "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 1.533348\n",
            "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 1.589568\n",
            "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 1.567988\n",
            "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 1.500382\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 1.520434\n",
            "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 1.471666\n",
            "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 1.564772\n",
            "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 1.573289\n",
            "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 1.542810\n",
            "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 1.573641\n",
            "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 1.500680\n",
            "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 1.507360\n",
            "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 1.525280\n",
            "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 1.460573\n",
            "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 1.448782\n",
            "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 1.441072\n",
            "\n",
            "Test set: Average loss: 0.6960, Accuracy: 7797/10000 (77.97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.490018\n",
            "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 1.454775\n",
            "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 1.525854\n",
            "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 1.569679\n",
            "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 1.537980\n",
            "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 1.467761\n",
            "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 1.486421\n",
            "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 1.355659\n",
            "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 1.444021\n",
            "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 1.467287\n",
            "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 1.418138\n",
            "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 1.510104\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 1.346058\n",
            "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 1.362112\n",
            "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 1.440205\n",
            "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 1.430004\n",
            "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 1.426895\n",
            "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 1.374914\n",
            "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 1.383346\n",
            "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 1.323647\n",
            "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 1.329080\n",
            "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 1.382762\n",
            "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 1.372216\n",
            "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 1.473028\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 1.425600\n",
            "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 1.320217\n",
            "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 1.359518\n",
            "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 1.316811\n",
            "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 1.268036\n",
            "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 1.338114\n",
            "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 1.286316\n",
            "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 1.293681\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 1.371044\n",
            "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 1.354712\n",
            "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 1.328332\n",
            "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 1.366996\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 1.210212\n",
            "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 1.146016\n",
            "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 1.307378\n",
            "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 1.245979\n",
            "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 1.263462\n",
            "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 1.310275\n",
            "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 1.293321\n",
            "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 1.234997\n",
            "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 1.325121\n",
            "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 1.271395\n",
            "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 1.333864\n",
            "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 1.209841\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 1.260522\n",
            "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 1.266514\n",
            "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 1.254092\n",
            "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 1.157579\n",
            "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 1.331031\n",
            "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 1.251868\n",
            "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 1.203561\n",
            "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 1.258679\n",
            "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 1.223405\n",
            "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 1.233468\n",
            "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 1.171997\n",
            "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 1.279891\n",
            "\n",
            "Test set: Average loss: 0.5793, Accuracy: 8223/10000 (82.23%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.197417\n",
            "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 1.167411\n",
            "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 1.128589\n",
            "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 1.164521\n",
            "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 1.190848\n",
            "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 1.169418\n",
            "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 1.240597\n",
            "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 1.271171\n",
            "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 1.149648\n",
            "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 1.134964\n",
            "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 1.098170\n",
            "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 1.111212\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 1.183207\n",
            "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 1.067198\n",
            "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 1.050852\n",
            "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 1.166867\n",
            "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 1.145626\n",
            "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 1.137071\n",
            "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 1.108779\n",
            "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 1.176254\n",
            "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 1.052285\n",
            "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 1.143222\n",
            "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 1.106913\n",
            "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 1.075088\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 1.110072\n",
            "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 1.168923\n",
            "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 1.087132\n",
            "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 1.085784\n",
            "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 1.024343\n",
            "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 1.122391\n",
            "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.973223\n",
            "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 0.948728\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 1.096314\n",
            "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 1.035226\n",
            "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 1.046816\n",
            "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 1.155601\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 1.079178\n",
            "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 0.966943\n",
            "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 1.046615\n",
            "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 1.004747\n",
            "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.996035\n",
            "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 0.980144\n",
            "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 1.032394\n",
            "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 0.975089\n",
            "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 0.953306\n",
            "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 1.012309\n",
            "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.957362\n",
            "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 0.940891\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 1.115029\n",
            "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 0.958507\n",
            "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.971830\n",
            "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 1.009808\n",
            "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.993266\n",
            "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 0.940533\n",
            "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 0.907540\n",
            "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.958431\n",
            "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.965800\n",
            "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 1.017057\n",
            "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.895574\n",
            "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 0.907673\n",
            "\n",
            "Test set: Average loss: 0.5200, Accuracy: 8538/10000 (85.38%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.027623\n",
            "Train Epoch: 5 [1000/60000 (2%)]\tLoss: 1.004500\n",
            "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 0.985113\n",
            "Train Epoch: 5 [3000/60000 (5%)]\tLoss: 0.987617\n",
            "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 0.848728\n",
            "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 0.955241\n",
            "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 0.903616\n",
            "Train Epoch: 5 [7000/60000 (12%)]\tLoss: 0.914135\n",
            "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.935512\n",
            "Train Epoch: 5 [9000/60000 (15%)]\tLoss: 0.931004\n",
            "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.942412\n",
            "Train Epoch: 5 [11000/60000 (18%)]\tLoss: 0.899187\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.910280\n",
            "Train Epoch: 5 [13000/60000 (22%)]\tLoss: 0.891299\n",
            "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 0.897079\n",
            "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 0.835273\n",
            "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.857574\n",
            "Train Epoch: 5 [17000/60000 (28%)]\tLoss: 0.922915\n",
            "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 0.919234\n",
            "Train Epoch: 5 [19000/60000 (32%)]\tLoss: 0.907276\n",
            "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.999366\n",
            "Train Epoch: 5 [21000/60000 (35%)]\tLoss: 0.911290\n",
            "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 0.816114\n",
            "Train Epoch: 5 [23000/60000 (38%)]\tLoss: 0.831186\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.889040\n",
            "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.937447\n",
            "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 0.878813\n",
            "Train Epoch: 5 [27000/60000 (45%)]\tLoss: 0.869468\n",
            "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 0.890875\n",
            "Train Epoch: 5 [29000/60000 (48%)]\tLoss: 0.863322\n",
            "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.829861\n",
            "Train Epoch: 5 [31000/60000 (52%)]\tLoss: 0.874199\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.861388\n",
            "Train Epoch: 5 [33000/60000 (55%)]\tLoss: 0.915145\n",
            "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 0.796471\n",
            "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 0.756280\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.869129\n",
            "Train Epoch: 5 [37000/60000 (62%)]\tLoss: 0.838787\n",
            "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 0.779815\n",
            "Train Epoch: 5 [39000/60000 (65%)]\tLoss: 0.869865\n",
            "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.891716\n",
            "Train Epoch: 5 [41000/60000 (68%)]\tLoss: 0.953369\n",
            "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 0.853609\n",
            "Train Epoch: 5 [43000/60000 (72%)]\tLoss: 0.783327\n",
            "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 0.770427\n",
            "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.817776\n",
            "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 0.832639\n",
            "Train Epoch: 5 [47000/60000 (78%)]\tLoss: 0.796428\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.878686\n",
            "Train Epoch: 5 [49000/60000 (82%)]\tLoss: 0.909359\n",
            "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.770391\n",
            "Train Epoch: 5 [51000/60000 (85%)]\tLoss: 0.819857\n",
            "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 0.762504\n",
            "Train Epoch: 5 [53000/60000 (88%)]\tLoss: 0.892485\n",
            "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 0.833906\n",
            "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 0.845896\n",
            "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.760796\n",
            "Train Epoch: 5 [57000/60000 (95%)]\tLoss: 0.875509\n",
            "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 0.772894\n",
            "Train Epoch: 5 [59000/60000 (98%)]\tLoss: 0.739873\n",
            "\n",
            "Test set: Average loss: 0.4673, Accuracy: 8788/10000 (87.88%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.882862\n",
            "Train Epoch: 6 [1000/60000 (2%)]\tLoss: 0.792353\n",
            "Train Epoch: 6 [2000/60000 (3%)]\tLoss: 0.751392\n",
            "Train Epoch: 6 [3000/60000 (5%)]\tLoss: 0.789476\n",
            "Train Epoch: 6 [4000/60000 (7%)]\tLoss: 0.799968\n",
            "Train Epoch: 6 [5000/60000 (8%)]\tLoss: 0.739189\n",
            "Train Epoch: 6 [6000/60000 (10%)]\tLoss: 0.768208\n",
            "Train Epoch: 6 [7000/60000 (12%)]\tLoss: 0.877211\n",
            "Train Epoch: 6 [8000/60000 (13%)]\tLoss: 0.882972\n",
            "Train Epoch: 6 [9000/60000 (15%)]\tLoss: 0.788683\n",
            "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 0.783504\n",
            "Train Epoch: 6 [11000/60000 (18%)]\tLoss: 0.826152\n",
            "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.808237\n",
            "Train Epoch: 6 [13000/60000 (22%)]\tLoss: 0.811087\n",
            "Train Epoch: 6 [14000/60000 (23%)]\tLoss: 0.760131\n",
            "Train Epoch: 6 [15000/60000 (25%)]\tLoss: 0.810952\n",
            "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.803475\n",
            "Train Epoch: 6 [17000/60000 (28%)]\tLoss: 0.857639\n",
            "Train Epoch: 6 [18000/60000 (30%)]\tLoss: 0.799358\n",
            "Train Epoch: 6 [19000/60000 (32%)]\tLoss: 0.800983\n",
            "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.783155\n",
            "Train Epoch: 6 [21000/60000 (35%)]\tLoss: 0.756895\n",
            "Train Epoch: 6 [22000/60000 (37%)]\tLoss: 0.724465\n",
            "Train Epoch: 6 [23000/60000 (38%)]\tLoss: 0.712832\n",
            "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.796968\n",
            "Train Epoch: 6 [25000/60000 (42%)]\tLoss: 0.845649\n",
            "Train Epoch: 6 [26000/60000 (43%)]\tLoss: 0.725306\n",
            "Train Epoch: 6 [27000/60000 (45%)]\tLoss: 0.780645\n",
            "Train Epoch: 6 [28000/60000 (47%)]\tLoss: 0.823563\n",
            "Train Epoch: 6 [29000/60000 (48%)]\tLoss: 0.784524\n",
            "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 0.709301\n",
            "Train Epoch: 6 [31000/60000 (52%)]\tLoss: 0.814998\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.726746\n",
            "Train Epoch: 6 [33000/60000 (55%)]\tLoss: 0.740447\n",
            "Train Epoch: 6 [34000/60000 (57%)]\tLoss: 0.778914\n",
            "Train Epoch: 6 [35000/60000 (58%)]\tLoss: 0.688358\n",
            "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.786911\n",
            "Train Epoch: 6 [37000/60000 (62%)]\tLoss: 0.745605\n",
            "Train Epoch: 6 [38000/60000 (63%)]\tLoss: 0.798966\n",
            "Train Epoch: 6 [39000/60000 (65%)]\tLoss: 0.912522\n",
            "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.722681\n",
            "Train Epoch: 6 [41000/60000 (68%)]\tLoss: 0.775558\n",
            "Train Epoch: 6 [42000/60000 (70%)]\tLoss: 0.781249\n",
            "Train Epoch: 6 [43000/60000 (72%)]\tLoss: 0.756756\n",
            "Train Epoch: 6 [44000/60000 (73%)]\tLoss: 0.756978\n",
            "Train Epoch: 6 [45000/60000 (75%)]\tLoss: 0.807057\n",
            "Train Epoch: 6 [46000/60000 (77%)]\tLoss: 0.912448\n",
            "Train Epoch: 6 [47000/60000 (78%)]\tLoss: 0.741289\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.865257\n",
            "Train Epoch: 6 [49000/60000 (82%)]\tLoss: 0.730959\n",
            "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 0.739544\n",
            "Train Epoch: 6 [51000/60000 (85%)]\tLoss: 0.840021\n",
            "Train Epoch: 6 [52000/60000 (87%)]\tLoss: 0.759208\n",
            "Train Epoch: 6 [53000/60000 (88%)]\tLoss: 0.672131\n",
            "Train Epoch: 6 [54000/60000 (90%)]\tLoss: 0.803606\n",
            "Train Epoch: 6 [55000/60000 (92%)]\tLoss: 0.710220\n",
            "Train Epoch: 6 [56000/60000 (93%)]\tLoss: 0.819339\n",
            "Train Epoch: 6 [57000/60000 (95%)]\tLoss: 0.746390\n",
            "Train Epoch: 6 [58000/60000 (97%)]\tLoss: 0.850358\n",
            "Train Epoch: 6 [59000/60000 (98%)]\tLoss: 0.736074\n",
            "\n",
            "Test set: Average loss: 0.4587, Accuracy: 8809/10000 (88.09%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.772620\n",
            "Train Epoch: 7 [1000/60000 (2%)]\tLoss: 0.695472\n",
            "Train Epoch: 7 [2000/60000 (3%)]\tLoss: 0.730809\n",
            "Train Epoch: 7 [3000/60000 (5%)]\tLoss: 0.875578\n",
            "Train Epoch: 7 [4000/60000 (7%)]\tLoss: 0.759775\n",
            "Train Epoch: 7 [5000/60000 (8%)]\tLoss: 0.739435\n",
            "Train Epoch: 7 [6000/60000 (10%)]\tLoss: 0.722619\n",
            "Train Epoch: 7 [7000/60000 (12%)]\tLoss: 0.753807\n",
            "Train Epoch: 7 [8000/60000 (13%)]\tLoss: 0.755689\n",
            "Train Epoch: 7 [9000/60000 (15%)]\tLoss: 0.629441\n",
            "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 0.750345\n",
            "Train Epoch: 7 [11000/60000 (18%)]\tLoss: 0.731582\n",
            "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.785270\n",
            "Train Epoch: 7 [13000/60000 (22%)]\tLoss: 0.788735\n",
            "Train Epoch: 7 [14000/60000 (23%)]\tLoss: 0.781486\n",
            "Train Epoch: 7 [15000/60000 (25%)]\tLoss: 0.762373\n",
            "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.780688\n",
            "Train Epoch: 7 [17000/60000 (28%)]\tLoss: 0.834976\n",
            "Train Epoch: 7 [18000/60000 (30%)]\tLoss: 0.836703\n",
            "Train Epoch: 7 [19000/60000 (32%)]\tLoss: 0.706047\n",
            "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.778251\n",
            "Train Epoch: 7 [21000/60000 (35%)]\tLoss: 0.700410\n",
            "Train Epoch: 7 [22000/60000 (37%)]\tLoss: 0.865572\n",
            "Train Epoch: 7 [23000/60000 (38%)]\tLoss: 0.794873\n",
            "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.666288\n",
            "Train Epoch: 7 [25000/60000 (42%)]\tLoss: 0.756188\n",
            "Train Epoch: 7 [26000/60000 (43%)]\tLoss: 0.701929\n",
            "Train Epoch: 7 [27000/60000 (45%)]\tLoss: 0.820338\n",
            "Train Epoch: 7 [28000/60000 (47%)]\tLoss: 0.646223\n",
            "Train Epoch: 7 [29000/60000 (48%)]\tLoss: 0.687092\n",
            "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 0.736183\n",
            "Train Epoch: 7 [31000/60000 (52%)]\tLoss: 0.735796\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.730839\n",
            "Train Epoch: 7 [33000/60000 (55%)]\tLoss: 0.782304\n",
            "Train Epoch: 7 [34000/60000 (57%)]\tLoss: 0.796594\n",
            "Train Epoch: 7 [35000/60000 (58%)]\tLoss: 0.636928\n",
            "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.667462\n",
            "Train Epoch: 7 [37000/60000 (62%)]\tLoss: 0.836532\n",
            "Train Epoch: 7 [38000/60000 (63%)]\tLoss: 0.812741\n",
            "Train Epoch: 7 [39000/60000 (65%)]\tLoss: 0.813973\n",
            "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.763355\n",
            "Train Epoch: 7 [41000/60000 (68%)]\tLoss: 0.676417\n",
            "Train Epoch: 7 [42000/60000 (70%)]\tLoss: 0.730554\n",
            "Train Epoch: 7 [43000/60000 (72%)]\tLoss: 0.751015\n",
            "Train Epoch: 7 [44000/60000 (73%)]\tLoss: 0.633143\n",
            "Train Epoch: 7 [45000/60000 (75%)]\tLoss: 0.688494\n",
            "Train Epoch: 7 [46000/60000 (77%)]\tLoss: 0.850031\n",
            "Train Epoch: 7 [47000/60000 (78%)]\tLoss: 0.744241\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.822054\n",
            "Train Epoch: 7 [49000/60000 (82%)]\tLoss: 0.753802\n",
            "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 0.701225\n",
            "Train Epoch: 7 [51000/60000 (85%)]\tLoss: 0.734731\n",
            "Train Epoch: 7 [52000/60000 (87%)]\tLoss: 0.730729\n",
            "Train Epoch: 7 [53000/60000 (88%)]\tLoss: 0.757903\n",
            "Train Epoch: 7 [54000/60000 (90%)]\tLoss: 0.815788\n",
            "Train Epoch: 7 [55000/60000 (92%)]\tLoss: 0.786112\n",
            "Train Epoch: 7 [56000/60000 (93%)]\tLoss: 0.772951\n",
            "Train Epoch: 7 [57000/60000 (95%)]\tLoss: 0.815563\n",
            "Train Epoch: 7 [58000/60000 (97%)]\tLoss: 0.861962\n",
            "Train Epoch: 7 [59000/60000 (98%)]\tLoss: 0.741669\n",
            "\n",
            "Test set: Average loss: 0.4578, Accuracy: 8850/10000 (88.50%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.739176\n",
            "Train Epoch: 8 [1000/60000 (2%)]\tLoss: 0.832166\n",
            "Train Epoch: 8 [2000/60000 (3%)]\tLoss: 0.882033\n",
            "Train Epoch: 8 [3000/60000 (5%)]\tLoss: 0.747895\n",
            "Train Epoch: 8 [4000/60000 (7%)]\tLoss: 0.794196\n",
            "Train Epoch: 8 [5000/60000 (8%)]\tLoss: 0.679974\n",
            "Train Epoch: 8 [6000/60000 (10%)]\tLoss: 0.717346\n",
            "Train Epoch: 8 [7000/60000 (12%)]\tLoss: 0.674383\n",
            "Train Epoch: 8 [8000/60000 (13%)]\tLoss: 0.743967\n",
            "Train Epoch: 8 [9000/60000 (15%)]\tLoss: 0.604077\n",
            "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 0.782907\n",
            "Train Epoch: 8 [11000/60000 (18%)]\tLoss: 0.700785\n",
            "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.800804\n",
            "Train Epoch: 8 [13000/60000 (22%)]\tLoss: 0.740546\n",
            "Train Epoch: 8 [14000/60000 (23%)]\tLoss: 0.760960\n",
            "Train Epoch: 8 [15000/60000 (25%)]\tLoss: 0.648797\n",
            "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.693044\n",
            "Train Epoch: 8 [17000/60000 (28%)]\tLoss: 0.807519\n",
            "Train Epoch: 8 [18000/60000 (30%)]\tLoss: 0.724148\n",
            "Train Epoch: 8 [19000/60000 (32%)]\tLoss: 0.687620\n",
            "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.809289\n",
            "Train Epoch: 8 [21000/60000 (35%)]\tLoss: 0.883919\n",
            "Train Epoch: 8 [22000/60000 (37%)]\tLoss: 0.754197\n",
            "Train Epoch: 8 [23000/60000 (38%)]\tLoss: 0.735342\n",
            "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.745541\n",
            "Train Epoch: 8 [25000/60000 (42%)]\tLoss: 0.756316\n",
            "Train Epoch: 8 [26000/60000 (43%)]\tLoss: 0.774388\n",
            "Train Epoch: 8 [27000/60000 (45%)]\tLoss: 0.736418\n",
            "Train Epoch: 8 [28000/60000 (47%)]\tLoss: 0.827262\n",
            "Train Epoch: 8 [29000/60000 (48%)]\tLoss: 0.768122\n",
            "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 0.772024\n",
            "Train Epoch: 8 [31000/60000 (52%)]\tLoss: 0.780023\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.773180\n",
            "Train Epoch: 8 [33000/60000 (55%)]\tLoss: 0.711393\n",
            "Train Epoch: 8 [34000/60000 (57%)]\tLoss: 0.772534\n",
            "Train Epoch: 8 [35000/60000 (58%)]\tLoss: 0.680203\n",
            "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.796935\n",
            "Train Epoch: 8 [37000/60000 (62%)]\tLoss: 0.803776\n",
            "Train Epoch: 8 [38000/60000 (63%)]\tLoss: 0.729607\n",
            "Train Epoch: 8 [39000/60000 (65%)]\tLoss: 0.701667\n",
            "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.861399\n",
            "Train Epoch: 8 [41000/60000 (68%)]\tLoss: 0.711484\n",
            "Train Epoch: 8 [42000/60000 (70%)]\tLoss: 0.858257\n",
            "Train Epoch: 8 [43000/60000 (72%)]\tLoss: 0.754297\n",
            "Train Epoch: 8 [44000/60000 (73%)]\tLoss: 0.844085\n",
            "Train Epoch: 8 [45000/60000 (75%)]\tLoss: 0.782387\n",
            "Train Epoch: 8 [46000/60000 (77%)]\tLoss: 0.661590\n",
            "Train Epoch: 8 [47000/60000 (78%)]\tLoss: 0.651986\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.691031\n",
            "Train Epoch: 8 [49000/60000 (82%)]\tLoss: 0.701118\n",
            "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 0.748317\n",
            "Train Epoch: 8 [51000/60000 (85%)]\tLoss: 0.654813\n",
            "Train Epoch: 8 [52000/60000 (87%)]\tLoss: 0.759317\n",
            "Train Epoch: 8 [53000/60000 (88%)]\tLoss: 0.706216\n",
            "Train Epoch: 8 [54000/60000 (90%)]\tLoss: 0.698926\n",
            "Train Epoch: 8 [55000/60000 (92%)]\tLoss: 0.802345\n",
            "Train Epoch: 8 [56000/60000 (93%)]\tLoss: 0.744961\n",
            "Train Epoch: 8 [57000/60000 (95%)]\tLoss: 0.720831\n",
            "Train Epoch: 8 [58000/60000 (97%)]\tLoss: 0.709933\n",
            "Train Epoch: 8 [59000/60000 (98%)]\tLoss: 0.739430\n",
            "\n",
            "Test set: Average loss: 0.4482, Accuracy: 8856/10000 (88.56%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.753766\n",
            "Train Epoch: 9 [1000/60000 (2%)]\tLoss: 0.748900\n",
            "Train Epoch: 9 [2000/60000 (3%)]\tLoss: 0.726372\n",
            "Train Epoch: 9 [3000/60000 (5%)]\tLoss: 0.719460\n",
            "Train Epoch: 9 [4000/60000 (7%)]\tLoss: 0.765355\n",
            "Train Epoch: 9 [5000/60000 (8%)]\tLoss: 0.756957\n",
            "Train Epoch: 9 [6000/60000 (10%)]\tLoss: 0.748993\n",
            "Train Epoch: 9 [7000/60000 (12%)]\tLoss: 0.646162\n",
            "Train Epoch: 9 [8000/60000 (13%)]\tLoss: 0.706910\n",
            "Train Epoch: 9 [9000/60000 (15%)]\tLoss: 0.752522\n",
            "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 0.682119\n",
            "Train Epoch: 9 [11000/60000 (18%)]\tLoss: 0.667985\n",
            "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.715838\n",
            "Train Epoch: 9 [13000/60000 (22%)]\tLoss: 0.778958\n",
            "Train Epoch: 9 [14000/60000 (23%)]\tLoss: 0.776228\n",
            "Train Epoch: 9 [15000/60000 (25%)]\tLoss: 0.741665\n",
            "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.852801\n",
            "Train Epoch: 9 [17000/60000 (28%)]\tLoss: 0.678760\n",
            "Train Epoch: 9 [18000/60000 (30%)]\tLoss: 0.721899\n",
            "Train Epoch: 9 [19000/60000 (32%)]\tLoss: 0.794407\n",
            "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.803622\n",
            "Train Epoch: 9 [21000/60000 (35%)]\tLoss: 0.705209\n",
            "Train Epoch: 9 [22000/60000 (37%)]\tLoss: 0.635518\n",
            "Train Epoch: 9 [23000/60000 (38%)]\tLoss: 0.703020\n",
            "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.707149\n",
            "Train Epoch: 9 [25000/60000 (42%)]\tLoss: 0.815201\n",
            "Train Epoch: 9 [26000/60000 (43%)]\tLoss: 0.731094\n",
            "Train Epoch: 9 [27000/60000 (45%)]\tLoss: 0.758319\n",
            "Train Epoch: 9 [28000/60000 (47%)]\tLoss: 0.726732\n",
            "Train Epoch: 9 [29000/60000 (48%)]\tLoss: 0.645371\n",
            "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 0.703860\n",
            "Train Epoch: 9 [31000/60000 (52%)]\tLoss: 0.644538\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.705040\n",
            "Train Epoch: 9 [33000/60000 (55%)]\tLoss: 0.737565\n",
            "Train Epoch: 9 [34000/60000 (57%)]\tLoss: 0.739242\n",
            "Train Epoch: 9 [35000/60000 (58%)]\tLoss: 0.751688\n",
            "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.765832\n",
            "Train Epoch: 9 [37000/60000 (62%)]\tLoss: 0.680523\n",
            "Train Epoch: 9 [38000/60000 (63%)]\tLoss: 0.766573\n",
            "Train Epoch: 9 [39000/60000 (65%)]\tLoss: 0.704954\n",
            "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.748366\n",
            "Train Epoch: 9 [41000/60000 (68%)]\tLoss: 0.692567\n",
            "Train Epoch: 9 [42000/60000 (70%)]\tLoss: 0.762990\n",
            "Train Epoch: 9 [43000/60000 (72%)]\tLoss: 0.837434\n",
            "Train Epoch: 9 [44000/60000 (73%)]\tLoss: 0.754001\n",
            "Train Epoch: 9 [45000/60000 (75%)]\tLoss: 0.741581\n",
            "Train Epoch: 9 [46000/60000 (77%)]\tLoss: 0.638061\n",
            "Train Epoch: 9 [47000/60000 (78%)]\tLoss: 0.684387\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.686690\n",
            "Train Epoch: 9 [49000/60000 (82%)]\tLoss: 0.754999\n",
            "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 0.674417\n",
            "Train Epoch: 9 [51000/60000 (85%)]\tLoss: 0.647867\n",
            "Train Epoch: 9 [52000/60000 (87%)]\tLoss: 0.735850\n",
            "Train Epoch: 9 [53000/60000 (88%)]\tLoss: 0.720970\n",
            "Train Epoch: 9 [54000/60000 (90%)]\tLoss: 0.665745\n",
            "Train Epoch: 9 [55000/60000 (92%)]\tLoss: 0.803136\n",
            "Train Epoch: 9 [56000/60000 (93%)]\tLoss: 0.799731\n",
            "Train Epoch: 9 [57000/60000 (95%)]\tLoss: 0.746280\n",
            "Train Epoch: 9 [58000/60000 (97%)]\tLoss: 0.728157\n",
            "Train Epoch: 9 [59000/60000 (98%)]\tLoss: 0.672190\n",
            "\n",
            "Test set: Average loss: 0.4427, Accuracy: 8901/10000 (89.01%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.759347\n",
            "Train Epoch: 10 [1000/60000 (2%)]\tLoss: 0.755685\n",
            "Train Epoch: 10 [2000/60000 (3%)]\tLoss: 0.685118\n",
            "Train Epoch: 10 [3000/60000 (5%)]\tLoss: 0.701544\n",
            "Train Epoch: 10 [4000/60000 (7%)]\tLoss: 0.728552\n",
            "Train Epoch: 10 [5000/60000 (8%)]\tLoss: 0.644090\n",
            "Train Epoch: 10 [6000/60000 (10%)]\tLoss: 0.769560\n",
            "Train Epoch: 10 [7000/60000 (12%)]\tLoss: 0.661646\n",
            "Train Epoch: 10 [8000/60000 (13%)]\tLoss: 0.670774\n",
            "Train Epoch: 10 [9000/60000 (15%)]\tLoss: 0.775769\n",
            "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 0.669391\n",
            "Train Epoch: 10 [11000/60000 (18%)]\tLoss: 0.693252\n",
            "Train Epoch: 10 [12000/60000 (20%)]\tLoss: 0.639512\n",
            "Train Epoch: 10 [13000/60000 (22%)]\tLoss: 0.785827\n",
            "Train Epoch: 10 [14000/60000 (23%)]\tLoss: 0.788930\n",
            "Train Epoch: 10 [15000/60000 (25%)]\tLoss: 0.669171\n",
            "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.706216\n",
            "Train Epoch: 10 [17000/60000 (28%)]\tLoss: 0.754265\n",
            "Train Epoch: 10 [18000/60000 (30%)]\tLoss: 0.728597\n",
            "Train Epoch: 10 [19000/60000 (32%)]\tLoss: 0.785305\n",
            "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 0.711985\n",
            "Train Epoch: 10 [21000/60000 (35%)]\tLoss: 0.675163\n",
            "Train Epoch: 10 [22000/60000 (37%)]\tLoss: 0.805424\n",
            "Train Epoch: 10 [23000/60000 (38%)]\tLoss: 0.707851\n",
            "Train Epoch: 10 [24000/60000 (40%)]\tLoss: 0.767893\n",
            "Train Epoch: 10 [25000/60000 (42%)]\tLoss: 0.706782\n",
            "Train Epoch: 10 [26000/60000 (43%)]\tLoss: 0.697477\n",
            "Train Epoch: 10 [27000/60000 (45%)]\tLoss: 0.705651\n",
            "Train Epoch: 10 [28000/60000 (47%)]\tLoss: 0.610357\n",
            "Train Epoch: 10 [29000/60000 (48%)]\tLoss: 0.741538\n",
            "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 0.617308\n",
            "Train Epoch: 10 [31000/60000 (52%)]\tLoss: 0.810116\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.811669\n",
            "Train Epoch: 10 [33000/60000 (55%)]\tLoss: 0.769217\n",
            "Train Epoch: 10 [34000/60000 (57%)]\tLoss: 0.716352\n",
            "Train Epoch: 10 [35000/60000 (58%)]\tLoss: 0.781911\n",
            "Train Epoch: 10 [36000/60000 (60%)]\tLoss: 0.698105\n",
            "Train Epoch: 10 [37000/60000 (62%)]\tLoss: 0.664055\n",
            "Train Epoch: 10 [38000/60000 (63%)]\tLoss: 0.716688\n",
            "Train Epoch: 10 [39000/60000 (65%)]\tLoss: 0.760704\n",
            "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 0.673425\n",
            "Train Epoch: 10 [41000/60000 (68%)]\tLoss: 0.724176\n",
            "Train Epoch: 10 [42000/60000 (70%)]\tLoss: 0.771697\n",
            "Train Epoch: 10 [43000/60000 (72%)]\tLoss: 0.758693\n",
            "Train Epoch: 10 [44000/60000 (73%)]\tLoss: 0.712393\n",
            "Train Epoch: 10 [45000/60000 (75%)]\tLoss: 0.696049\n",
            "Train Epoch: 10 [46000/60000 (77%)]\tLoss: 0.743328\n",
            "Train Epoch: 10 [47000/60000 (78%)]\tLoss: 0.647266\n",
            "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.653052\n",
            "Train Epoch: 10 [49000/60000 (82%)]\tLoss: 0.783323\n",
            "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 0.775117\n",
            "Train Epoch: 10 [51000/60000 (85%)]\tLoss: 0.676142\n",
            "Train Epoch: 10 [52000/60000 (87%)]\tLoss: 0.623272\n",
            "Train Epoch: 10 [53000/60000 (88%)]\tLoss: 0.735863\n",
            "Train Epoch: 10 [54000/60000 (90%)]\tLoss: 0.692311\n",
            "Train Epoch: 10 [55000/60000 (92%)]\tLoss: 0.649490\n",
            "Train Epoch: 10 [56000/60000 (93%)]\tLoss: 0.779848\n",
            "Train Epoch: 10 [57000/60000 (95%)]\tLoss: 0.783487\n",
            "Train Epoch: 10 [58000/60000 (97%)]\tLoss: 0.706402\n",
            "Train Epoch: 10 [59000/60000 (98%)]\tLoss: 0.807492\n",
            "\n",
            "Test set: Average loss: 0.4488, Accuracy: 8876/10000 (88.76%)\n",
            "\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.653769\n",
            "Train Epoch: 11 [1000/60000 (2%)]\tLoss: 0.647576\n",
            "Train Epoch: 11 [2000/60000 (3%)]\tLoss: 0.714769\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvuBnKAAGSPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model, 'binary_mnist.pth.tar')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}